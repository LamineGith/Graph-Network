{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W - Colab 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In this Colab, you will write a pipeline for **learning node embeddings** in a graph. You will go through the following 3 steps:\n",
        "\n",
        "1.   To start, you will load the familiar [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club) from Colab 0. You will explore multiple graph statistics over this graph.\n",
        "2.   You will then work to transform the graph structure into a PyTorch tensor so that you can perform machine learning over the graph.\n",
        "\n",
        "3. Finally, you will write your first graph learning algorithm: a node embedding model. For simplicity, your model is simpler than the DeepWalk and node2vec algorithms taught in Module 1, Unit 1.2 - Node Embeddings. Nevertheless, it will still be rewarding and challenging, as you will write the whole procedure from scratch via PyTorch.\n",
        "\n",
        "Let's get started!\n",
        "\n",
        "**Note**: Make sure to **sequentially run all the cells** so that the intermediate variables / packages will carry over to the next cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvduTt3oKimg"
      },
      "source": [
        "## Building + Debugging Notes\n",
        "While working through this Colab and future Colabs, we strongly encourage you to follow a couple of building / debugging strategies:\n",
        "- During debugging make sure to run your notebook using the CPU runtime. You can change the notebook runtime by selecting `Runtime` and then `Change runtime type`. From the dropdown, select `None` as the `hardware accelerator`.\n",
        "- When working with PyTorch and Neural Network models, understanding the shapes of different tensors, especially the input and output tensors is incredibly helpful.\n",
        "- When training models, it is helpful to start by only running 1 epoch or even just a couple of batch iterations. This way you can check that all your tensor shapes and logic match up, while also tracking expected behavior, such as a decreasing training loss. Remember to comment out / save the default number of epochs that we provide you.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwwq0nSdmsOL"
      },
      "source": [
        "# 1) Graph Basics\n",
        "To start, load the [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club), a classical graph in network science. As discussed in the introduction, you will begin by exploring multiple graph statistics for this graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDkpByYYfSzb"
      },
      "source": [
        "## Setup\n",
        "As introduced in Colab 0, NetworkX is a powerful package for storing and manipluating graphs. We will heavily rely on NetworkX throughout this Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VWPkJjPAfVNW"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqUnYT5qUZYh"
      },
      "source": [
        "## Zachary's karate club network\n",
        "\n",
        "The [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club) is a social network graph of 34 members of a karate club, where links exist between members who have interacted outside the club."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VIETqEfrfy5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e77885-28b5-42f3-94eb-f3baf0394818"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "networkx.classes.graph.Graph"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "G = nx.karate_club_graph()\n",
        "\n",
        "# G is an undirected graph\n",
        "\n",
        "type(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hDvf3nm-ors4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "bb768565-c1d8-444f-b296-d3f61e328f75"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize the graph\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  nx.draw(G, with_labels = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX25Y1CrYmgN"
      },
      "source": [
        "## Question 1: What is the average degree of the karate club network? (1 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AUhES1VYo3tB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "361bfc55-08e7-47c7-e3b5-47be55e868d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average degree of karate club network is 5\n"
          ]
        }
      ],
      "source": [
        "def average_degree(num_edges, num_nodes):\n",
        "  # TODO: Implement a function that takes the number of edges\n",
        "  # and number of nodes of a graph and returns the average node degree of \n",
        "  # the graph. Round the result to nearest integer (for example \n",
        "  # 3.3 will be rounded to 3 and 3.7 will be rounded to 4).\n",
        "\n",
        "  avg_degree = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: Do not import any other Python package\n",
        "  ## 2: Do not use any function from NetworkX\n",
        "  avg_degree = round(2*num_edges / num_nodes)\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return avg_degree\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  num_edges = G.number_of_edges()\n",
        "  num_nodes = G.number_of_nodes()\n",
        "  avg_degree = average_degree(num_edges, num_nodes)\n",
        "  print(\"Average degree of karate club network is {}\".format(avg_degree))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk02fD4vYmZI"
      },
      "source": [
        "## Question 2: What is the average clustering coefficient of the karate club network? (1 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k15XKEto1aYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "702fbe0a-04a2-45b5-eeb3-b9be37093dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average clustering coefficient of karate club network is 0.57\n"
          ]
        }
      ],
      "source": [
        "def average_clustering_coefficient(G):\n",
        "  # TODO: Implement a function that takes a nx.Graph\n",
        "  # and returns the average clustering coefficient. Round \n",
        "  # the result to 2 decimal places (for example 3.333 will\n",
        "  # be rounded to 3.33 and 3.7571 will be rounded to 3.76)\n",
        "\n",
        "  avg_cluster_coef = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: Please use the appropriate NetworkX clustering function\n",
        "  ## https://networkx.org/documentation/stable/reference/algorithms/clustering.html\n",
        "  avg_cluster_coef = round(nx.average_clustering(G),2)\n",
        "  #########################################\n",
        "\n",
        "  return avg_cluster_coef\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  avg_cluster_coef = average_clustering_coefficient(G)\n",
        "  print(\"Average clustering coefficient of karate club network is {}\".format(avg_cluster_coef))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zghQ-AhXYmP4"
      },
      "source": [
        "## Question 3: What is the PageRank value for node 0 (node with id 0) after one PageRank iteration? (5 Points)\n",
        "\n",
        "Please complete the code block by implementing the PageRank equation: $r_j^{t+1} = [\\sum_{i \\rightarrow j} \\beta \\frac{r_i^t}{d_i}] + (1 - \\beta) \\frac{1}{N}$ to update the PageRank value of an arbitrary node j for the first time step $t = 0 \\rightarrow t = 1$.\n",
        "\n",
        "**NOTE:** $r_j^0 = 1 / |G|$ for all nodes j (where $|G|$ is the number of nodes in the graph). Namely, at $t=0$ every node is initialized with the same PageRank value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BOGdWjNc6O7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971c2730-51a8-4953-9f70-3ddee85984e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The PageRank value for node 0 after one iteration is 0.13\n"
          ]
        }
      ],
      "source": [
        "def one_iter_pagerank(G, beta, r0, node_id):\n",
        "  # TODO: Implement a function that takes as input a nx.Graph, beta, r0 \n",
        "  # and node_id. Then for the given node_id = j, compute rj_1 as \n",
        "  # the PageRank of the input node j at time t = 1 (i.e. after ONE iteration). \n",
        "  # \n",
        "  # Round the result to 2 decimal places (for example 3.333 will\n",
        "  # be rounded to 3.33 and 3.7571 will be rounded to 3.76)\n",
        "  #\n",
        "  # NOTE: rj_0 = r0 for every node j (i.e. each node is initialized with \n",
        "  # the same PageRank value at t = 0; thus we do not need an initial PageRank\n",
        "  # vector r).\n",
        "\n",
        " \n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: You should not use nx.pagerank!\n",
        "  rj_1 = 0\n",
        "\n",
        "  neighbors = [n for n in G[node_id]]\n",
        "  degrees = [d for _,d in G.degree(neighbors)]\n",
        "\n",
        "  for d in degrees:\n",
        "    #print(d)\n",
        "    rj_1 += beta*(r0/d)\n",
        "\n",
        "  rj_1 = round(rj_1 + (1-beta)/G.number_of_nodes(), 2)\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return rj_1\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  beta = 0.8\n",
        "  r0 = 1 / G.number_of_nodes()\n",
        "  node = 0\n",
        "  r0_1 = one_iter_pagerank(G, beta, r0, node)\n",
        "  print(\"The PageRank value for node 0 after one iteration is {}\".format(r0_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icTcOULeYmIu"
      },
      "source": [
        "## Question 4: What is the (raw) closeness centrality for the node with id=5 in the karate club network? (1 Points)\n",
        "\n",
        "The equation for closeness centrality is $c(v) = \\frac{1}{\\sum_{u \\neq v}\\text{shortest path length between } u \\text{ and } v}$. Remember that we want the raw (unnormalized) closeness centrality from Module 1, Unit 1.1 - Traditional Feature Based Methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XbCsq_tl-3ok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33fc771c-e188-4ff0-c892-b4651f059da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The karate club network has closeness centrality 0.01\n"
          ]
        }
      ],
      "source": [
        "def closeness_centrality(G, node=5):\n",
        "  # TODO: Implement a function that calculates closeness centrality \n",
        "  # for a node in the karate club network. G is the input karate club \n",
        "  # network and 'node' is the node id of the node that we are interested\n",
        "  # in. Please round the closeness centrality result to 2 decimal places.\n",
        "\n",
        "  closeness = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note:\n",
        "  ## 1: You can use networkx closeness centrality function.\n",
        "  ## 2: Notice that networkx closeness centrality returns the normalized \n",
        "  ## closeness directly, which is different from the raw (unnormalized) \n",
        "  ## one that we learned in the lecture.\n",
        "  # closeness = round(nx.centrality.closeness_centrality(G, node, wf_improved = False), 2)\n",
        "  closeness = round(nx.closeness_centrality(G,node) / (len(nx.node_connected_component(G, node)) - 1), 2)\n",
        "  #########################################\n",
        "\n",
        "  return closeness\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  node = 5\n",
        "  closeness = closeness_centrality(G, node=node)\n",
        "  print(\"The karate club network has closeness centrality {}\".format(closeness))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MxvowibYl4x"
      },
      "source": [
        "# 2) Graph to Tensor\n",
        "Now, you will work to transform the graph $G$ into a PyTorch tensor, so that you can perform machine learning over the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDA8PosrA-9V"
      },
      "source": [
        "## Setup\n",
        "Check if PyTorch is properly installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ntuPVat_BAf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1adefc93-c49b-4c57-c404-5962314cab08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fko_2wSKYlun"
      },
      "source": [
        "## PyTorch tensor basics\n",
        "\n",
        "Generate PyTorch tensor with all zeros, ones or random values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "W2ySw3m-A9qF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e74a42b-3248-4422-e32a-127fb826ef2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "tensor([[0.7322, 0.5877, 0.4053, 0.2367],\n",
            "        [0.0992, 0.4890, 0.7390, 0.0935],\n",
            "        [0.0010, 0.7460, 0.9516, 0.3853]])\n",
            "torch.Size([3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Generate 3 x 4 tensor with all ones\n",
        "ones = torch.ones(3, 4)\n",
        "print(ones)\n",
        "\n",
        "# Generate 3 x 4 tensor with all zeros\n",
        "zeros = torch.zeros(3, 4)\n",
        "print(zeros)\n",
        "\n",
        "# Generate 3 x 4 tensor with random values on the interval [0, 1)\n",
        "random_tensor = torch.rand(3, 4)\n",
        "print(random_tensor)\n",
        "\n",
        "# Get the shape of the tensor\n",
        "print(ones.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8mp66eHBxWC"
      },
      "source": [
        "PyTorch tensors contains elements for a single data type, the `dtype`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rQiOvKJJBwq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa1e977-6590-4747-8223-64f631d4b43c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "# Create a 3 x 4 tensor with all 32-bit floating point zeros\n",
        "zeros = torch.zeros(3, 4, dtype=torch.float32)\n",
        "print(zeros.dtype)\n",
        "\n",
        "# Change the tensor dtype to 64-bit integer\n",
        "zeros = zeros.type(torch.long)\n",
        "print(zeros.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9EfegIRDkk2"
      },
      "source": [
        "## Question 5: Get the edge list of the karate club network and transform it into `torch.LongTensor`. What is the `torch.sum` value of the `pos_edge_index` tensor? (2 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kEtVxMFID3ZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486dab2f-b689-4d56-8709-c51fa8158a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The pos_edge_index tensor has shape torch.Size([2, 78])\n",
            "The pos_edge_index tensor has sum value 2535\n"
          ]
        }
      ],
      "source": [
        "def graph_to_edge_list(G):\n",
        "  # TODO: Implement a function that returns the edge list of\n",
        "  # a nx.Graph. The returned edge_list should be a list of tuples\n",
        "  # where each tuple represents an edge between two nodes.\n",
        "\n",
        "  edge_list = []\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note:\n",
        "  ## Try to use simple networkx functions.\n",
        "  edge_list = list(G.edges)\n",
        "  #########################################\n",
        "\n",
        "  return edge_list\n",
        "\n",
        "def edge_list_to_tensor(edge_list):\n",
        "  # TODO: Implement a function that transforms an edge_list to a\n",
        "  # tensor. The input edge_list is a list of tuples and the resulting\n",
        "  # tensor should have the shape [2 x len(edge_list)].\n",
        "\n",
        "  edge_index = torch.tensor([])\n",
        "\n",
        "  ############# Your code here ############\n",
        "  edge_index = torch.tensor(edge_list, dtype=torch.long).permute(1,0)\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return edge_index\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  pos_edge_list = graph_to_edge_list(G)\n",
        "  pos_edge_index = edge_list_to_tensor(pos_edge_list)\n",
        "  print(\"The pos_edge_index tensor has shape {}\".format(pos_edge_index.shape))\n",
        "  print(\"The pos_edge_index tensor has sum value {}\".format(torch.sum(pos_edge_index)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBL-ZmdHWqIu"
      },
      "source": [
        "## Question 6: Implement a function that samples negative edges. A negative edge exists between nodes $u$ and $v$ if there is no edge between $u$ and $v$ in the original graph.\n",
        "\n",
        "## Then, write a short function to answer which edges (edge_1 - edge_5) can be negative edges in the karate club network? (7.5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9N8VT1f8-IJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69688720-c0ca-4abb-a265-0837a989ab56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The neg_edge_index tensor has shape torch.Size([2, 78])\n",
            "(7, 1) False\n",
            "(1, 33) True\n",
            "(33, 22) False\n",
            "(0, 4) False\n",
            "(4, 2) True\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def sample_negative_edges(G, num_neg_samples):\n",
        "  # TODO: Implement a function that returns a list of RANDOM negative edges.\n",
        "  # The number of sampled negative edges is num_neg_samples. You do not\n",
        "  # need to consider the corner case when the number of possible negative edges\n",
        "  # is less than num_neg_samples. It should be ok as long as your implementation \n",
        "  # works on the karate club network. \n",
        "  # \n",
        "  # In this implementation, self loops should not be considered as\n",
        "  # either positive or negative edge. Also, notice that \n",
        "  # the karate club network is an undirected graph; if (0, 1) is a positive \n",
        "  # edge, do you think (1, 0) can be a negative one?\n",
        "\n",
        "  # Set the random number generator seed\n",
        "  random.seed(1)\n",
        "\n",
        "  neg_edge_list = []\n",
        "  pos_edge_list = graph_to_edge_list(G)\n",
        "  for node1 in G.nodes():\n",
        "      for node2 in G.nodes():\n",
        "          if node1 >= node2: #ignore same pairs and take only a combination of two nodes since the graph is undirected (if we x,y do not take y,x)\n",
        "              #print(node1, node2)\n",
        "              continue\n",
        "          if (node1, node2) in pos_edge_list:\n",
        "              continue\n",
        "          neg_edge_list.append((node1, node2))\n",
        "  neg_edge_list = random.sample(neg_edge_list, num_neg_samples)\n",
        "\n",
        "  return neg_edge_list\n",
        "\n",
        "def check_negative_edge(G, edge):\n",
        "  # TODO: Implement a function that returns whether a given edge \n",
        "  # is a negative edge within the graph G.\n",
        "  is_negative_edge = False\n",
        "    \n",
        "  ############# Your code here ############\n",
        "  ## NOTE:\n",
        "  ## Check the definition of a negative edge from the question.\n",
        "  if (G.has_edge(edge[0],edge[1])):\n",
        "    is_negative_edge = False\n",
        "  else : \n",
        "    is_negative_edge = True\n",
        "     \n",
        "  #########################################\n",
        "\n",
        "  return is_negative_edge\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  # Sample 78 negative edges\n",
        "  neg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n",
        "\n",
        "  # Transform the negative edge list to tensor\n",
        "  neg_edge_index = edge_list_to_tensor(neg_edge_list)\n",
        "  print(\"The neg_edge_index tensor has shape {}\".format(neg_edge_index.shape))\n",
        "\n",
        "  # Which of following edges can be negative ones?\n",
        "  edge_1 = (7, 1)\n",
        "  edge_2 = (1, 33)\n",
        "  edge_3 = (33, 22)\n",
        "  edge_4 = (0, 4)\n",
        "  edge_5 = (4, 2)\n",
        "\n",
        "  for u, v in [edge_1, edge_2, edge_3, edge_4, edge_5]:\n",
        "    print ((u, v), check_negative_edge(G, (u, v)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk9Q-a-9qGsw"
      },
      "source": [
        "# 3) Node Emebedding Learning\n",
        "\n",
        "Finally, you write your first learning algorithm on graphs: **a node embedding model**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDBxRQcZ_dUH"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Lnqn9H6s_ehX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f51e75-80b2-4975-987f-6b977ce4f9bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gomAf8vxq0R"
      },
      "source": [
        "To write your node embedding model, you will heavily utilize the [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) module in PyTorch. Let us first explore how to use `nn.Embedding`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aRiWGuLAx5yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198c11e3-3a18-4e93-e95e-b527d6041abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample embedding layer: Embedding(4, 8)\n"
          ]
        }
      ],
      "source": [
        "# Initialize an embedding layer.\n",
        "# Suppose you want to have embedding for 4 items (e.g., nodes).\n",
        "# Each item is represented by an 8 dimensional vector.\n",
        "\n",
        "emb_sample = nn.Embedding(num_embeddings=4, embedding_dim=8)\n",
        "print('Sample embedding layer: {}'.format(emb_sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS9qQfeujEVh"
      },
      "source": [
        "You can select items from the embedding matrix by using Tensor indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9AGIfP4QEDr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3ad155-8c89-4ad0-caaa-8ce7e71c4a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4274,  0.2009, -1.2956,  0.3551,  0.9168,  0.4989, -0.6590,  0.9332]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "tensor([[ 0.4274,  0.2009, -1.2956,  0.3551,  0.9168,  0.4989, -0.6590,  0.9332],\n",
            "        [-1.0870,  0.1832, -0.6019, -0.2928,  0.3781, -0.2452,  0.2574,  0.8810]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "torch.Size([4, 8])\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Select an embedding in emb_sample\n",
        "id = torch.LongTensor([1])\n",
        "print(emb_sample(id))\n",
        "\n",
        "# Select multiple embeddings\n",
        "ids = torch.LongTensor([1, 3])\n",
        "print(emb_sample(ids))\n",
        "\n",
        "# Get the shape of the embedding weight matrix\n",
        "shape = emb_sample.weight.data.shape\n",
        "print(shape)\n",
        "\n",
        "# Overwrite the weight to tensor with all ones\n",
        "emb_sample.weight.data = torch.ones(shape)\n",
        "\n",
        "# Let's check if the emb is indeed initilized\n",
        "ids = torch.LongTensor([0, 3])\n",
        "print(emb_sample(ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MjBuDKaKIsM"
      },
      "source": [
        "Now, it's time to create a node embedding matrix for our graph!\n",
        "- Each node in the karate club network is represented by a **16 dimensional** vector.\n",
        "- Initalize the matrix using a **uniform distribution**, in the range of $[0, 1)$. We suggest using [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DMMHhO-iA2T"
      },
      "source": [
        "## Question 7: Implement a function creating the node embedding matrix. (2.5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hMszSwRPKGn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a84b0a70-b094-4ef0-ccd1-950dac44ef7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding: Embedding(34, 16)\n",
            "tensor([[-1.5256, -0.7502, -0.6540, -1.6095, -0.1002, -0.6092, -0.9798, -1.6091,\n",
            "         -0.7121,  0.3037, -0.7773, -0.2515, -0.2223,  1.6871,  0.2284,  0.4676],\n",
            "        [-0.9274,  0.5451,  0.0663, -0.4370,  0.7626,  0.4415,  1.1651,  2.0154,\n",
            "          0.1374,  0.9386, -0.1860, -0.6446,  1.5392, -0.8696, -3.3312, -0.7479]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Please do not change / reset the random seed\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def create_node_emb(num_node=34, embedding_dim=16):\n",
        "  # TODO: Implement a function that creates the node embedding matrix.\n",
        "  # Return a torch.nn.Embedding layer. You do not need to change \n",
        "  # the values of num_node and embedding_dim. The weight matrix of the returned \n",
        "  # layer should be initialized using torch.rand under uniform distribution on the interval [0, 1). \n",
        "\n",
        "  emb = None\n",
        "\n",
        "  ############# Your code here ############\n",
        "  emb = nn.Embedding(num_embeddings = num_node, embedding_dim = embedding_dim)\n",
        "  #########################################\n",
        "\n",
        "  return emb\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  emb = create_node_emb()\n",
        "  ids = torch.LongTensor([0, 3])\n",
        "\n",
        "  # Print the embedding layer\n",
        "  print(\"Embedding: {}\".format(emb))\n",
        "\n",
        "  # An example that gets the embeddings for node 0 and 3\n",
        "  print(emb(ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QfoANibTzyh"
      },
      "source": [
        "## Visualize the initial node embeddings\n",
        "One good way to understand an embedding matrix, is to visualize it in a 2D space.\n",
        "Here, we have implemented an embedding visualization function for you.\n",
        "We first do PCA to reduce the dimensionality of embeddings to a 2D space.\n",
        "Then, we visualize each point, colored by the community it belongs to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_LCoIkarhfYD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "666b9bce-d787-44ba-f586-a437b221c94a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def visualize_emb(emb):\n",
        "  X = emb.weight.data.numpy()\n",
        "  pca = PCA(n_components=2)\n",
        "  components = pca.fit_transform(X)\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  club1_x = []\n",
        "  club1_y = []\n",
        "  club2_x = []\n",
        "  club2_y = []\n",
        "  for node in G.nodes(data=True):\n",
        "    if node[1]['club'] == 'Mr. Hi':\n",
        "      club1_x.append(components[node[0]][0])\n",
        "      club1_y.append(components[node[0]][1])\n",
        "    else:\n",
        "      club2_x.append(components[node[0]][0])\n",
        "      club2_y.append(components[node[0]][1])\n",
        "  plt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\n",
        "  plt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# Visualize the initial random embeddding\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  visualize_emb(emb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQIyuEz9ANb2"
      },
      "source": [
        "## Question 8: Train your first embedding model by maximizing the dot product between positive edge node pairs and minimizng the dot product between negative edge node pairs in the graph. Through training see the best performance that you can get! You should experiment with changing a few of the hyper parameters to observe the effect on training. (10.0 Points)\n",
        "\n",
        "**NOTE**: There is no need to heavily hyper-parameter tune your model! We ask you to explore updating a couple of hyper-parameters primarily to explore their potential effects. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fBo5qUVQiA2V"
      },
      "outputs": [],
      "source": [
        "# The goal here is to obtain node embedding such that dot product is high when two nodes are connected and low otherwise. The purpose of sigmoid function here is to convert dot product scores into the values between 0 and 1\n",
        "# so if value of sigmoid is greater than 0.5 we can predict that there is an edge between two nodes. We can think that model outputs are probabilities of the edge existence between two nodes (positive edges).\n",
        "# Negative edges mean that there is no edge in the actual network. Then the model outputs (predictions) and ground truth labels are plugged into the loss function which in our case is a Binary Cross Entropy. \n",
        "# The loss function value determines a discrepancy between predictions and the ground truth. So our goal is to minimize it with Stochastic Gradient Descent algorithm because we want our model to be able to make correct predictions based on node embeddings.\n",
        "# The dimension of out is equal to the number of training examples, in our case it is torch.Size([156]).\n",
        "# The accuracy function returns the ratio between the number of correctly predicted examples and the total number of examples. In order to do this we need to compare our model predictions with ground truth labels.\n",
        "\n",
        "class EmbModel(torch.nn.Module):\n",
        "    def __init__(self, emb):\n",
        "        # TODO: Implement the init function that initializes self.convs, \n",
        "        # self.bns, and self.softmax.\n",
        "\n",
        "        super(EmbModel, self).__init__()\n",
        "\n",
        "        # The node embedding matrix\n",
        "        self.emb = emb\n",
        "\n",
        "    def forward(self, train_edge):\n",
        "\n",
        "        out = None\n",
        "\n",
        "        ############# Your code here ############\n",
        "        ## Note:\n",
        "        # (1) Get the embeddings of the nodes in train_edge\n",
        "        # (2) Compute the embedding dot product for each node \n",
        "        # pair (positive and negative edges)\n",
        "        # (3) Feed the dot product result into sigmoid\n",
        "        ## (~5 lines of code)\n",
        "\n",
        "        node_emb = emb(train_edge)\n",
        "        dot_product = torch.sum(node_emb[0] * node_emb[1], -1)\n",
        "        #dot_product=node_emb[0].mul(node_emb[1])\n",
        "        #dot_product_result=torch.sum(dot_product,1)\n",
        "        node_emb = emb(train_edge)\n",
        "        \n",
        "        sig = nn.Sigmoid()\n",
        "        out = sig(dot_product)\n",
        "        \n",
        "        #########################################\n",
        "  \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RDeQTNNxqH0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fff8039-3452-48a6-8188-dea1205b006e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 1.9265128374099731 Acc: 0.5\n",
            "Epoch: 1 Loss: 1.9174575805664062 Acc: 0.5\n",
            "Epoch: 2 Loss: 1.898826241493225 Acc: 0.5\n",
            "Epoch: 3 Loss: 1.8733841180801392 Acc: 0.5\n",
            "Epoch: 4 Loss: 1.8419336080551147 Acc: 0.5\n",
            "Epoch: 5 Loss: 1.8052453994750977 Acc: 0.5128\n",
            "Epoch: 6 Loss: 1.7634645700454712 Acc: 0.5192\n",
            "Epoch: 7 Loss: 1.7176810503005981 Acc: 0.5321\n",
            "Epoch: 8 Loss: 1.6683934926986694 Acc: 0.5321\n",
            "Epoch: 9 Loss: 1.617224097251892 Acc: 0.5449\n",
            "Epoch: 10 Loss: 1.5636976957321167 Acc: 0.5449\n",
            "Epoch: 11 Loss: 1.5089689493179321 Acc: 0.5449\n",
            "Epoch: 12 Loss: 1.4533318281173706 Acc: 0.5449\n",
            "Epoch: 13 Loss: 1.3974136114120483 Acc: 0.5449\n",
            "Epoch: 14 Loss: 1.3414995670318604 Acc: 0.5513\n",
            "Epoch: 15 Loss: 1.286049723625183 Acc: 0.5641\n",
            "Epoch: 16 Loss: 1.2313560247421265 Acc: 0.5641\n",
            "Epoch: 17 Loss: 1.1777344942092896 Acc: 0.5769\n",
            "Epoch: 18 Loss: 1.1253957748413086 Acc: 0.5769\n",
            "Epoch: 19 Loss: 1.074571967124939 Acc: 0.5833\n",
            "Epoch: 20 Loss: 1.0254008769989014 Acc: 0.5962\n",
            "Epoch: 21 Loss: 0.9780074954032898 Acc: 0.6154\n",
            "Epoch: 22 Loss: 0.9324520826339722 Acc: 0.6538\n",
            "Epoch: 23 Loss: 0.8887779116630554 Acc: 0.6603\n",
            "Epoch: 24 Loss: 0.8469830751419067 Acc: 0.6731\n",
            "Epoch: 25 Loss: 0.807056188583374 Acc: 0.6859\n",
            "Epoch: 26 Loss: 0.7689608335494995 Acc: 0.7051\n",
            "Epoch: 27 Loss: 0.7326492667198181 Acc: 0.7179\n",
            "Epoch: 28 Loss: 0.6980665922164917 Acc: 0.7244\n",
            "Epoch: 29 Loss: 0.6651524305343628 Acc: 0.7372\n",
            "Epoch: 30 Loss: 0.6338440179824829 Acc: 0.75\n",
            "Epoch: 31 Loss: 0.6040776371955872 Acc: 0.7564\n",
            "Epoch: 32 Loss: 0.5757903456687927 Acc: 0.7692\n",
            "Epoch: 33 Loss: 0.5489212870597839 Acc: 0.7756\n",
            "Epoch: 34 Loss: 0.5234123468399048 Acc: 0.7885\n",
            "Epoch: 35 Loss: 0.4992085099220276 Acc: 0.7885\n",
            "Epoch: 36 Loss: 0.47625863552093506 Acc: 0.8013\n",
            "Epoch: 37 Loss: 0.4545157849788666 Acc: 0.8205\n",
            "Epoch: 38 Loss: 0.43393659591674805 Acc: 0.8333\n",
            "Epoch: 39 Loss: 0.41448119282722473 Acc: 0.8462\n",
            "Epoch: 40 Loss: 0.39611223340034485 Acc: 0.8462\n",
            "Epoch: 41 Loss: 0.37879323959350586 Acc: 0.8462\n",
            "Epoch: 42 Loss: 0.36248743534088135 Acc: 0.8462\n",
            "Epoch: 43 Loss: 0.34715625643730164 Acc: 0.8462\n",
            "Epoch: 44 Loss: 0.3327591121196747 Acc: 0.859\n",
            "Epoch: 45 Loss: 0.3192529082298279 Acc: 0.859\n",
            "Epoch: 46 Loss: 0.3065926134586334 Acc: 0.8654\n",
            "Epoch: 47 Loss: 0.2947312891483307 Acc: 0.8718\n",
            "Epoch: 48 Loss: 0.2836209237575531 Acc: 0.8846\n",
            "Epoch: 49 Loss: 0.2732129693031311 Acc: 0.8974\n",
            "Epoch: 50 Loss: 0.26345881819725037 Acc: 0.9167\n",
            "Epoch: 51 Loss: 0.254310667514801 Acc: 0.9295\n",
            "Epoch: 52 Loss: 0.24572232365608215 Acc: 0.9295\n",
            "Epoch: 53 Loss: 0.23764961957931519 Acc: 0.9359\n",
            "Epoch: 54 Loss: 0.23005089163780212 Acc: 0.9423\n",
            "Epoch: 55 Loss: 0.2228875756263733 Acc: 0.9423\n",
            "Epoch: 56 Loss: 0.21612387895584106 Acc: 0.9551\n",
            "Epoch: 57 Loss: 0.2097272127866745 Acc: 0.9615\n",
            "Epoch: 58 Loss: 0.20366786420345306 Acc: 0.9615\n",
            "Epoch: 59 Loss: 0.19791892170906067 Acc: 0.9615\n",
            "Epoch: 60 Loss: 0.19245608150959015 Acc: 0.9615\n",
            "Epoch: 61 Loss: 0.18725743889808655 Acc: 0.9615\n",
            "Epoch: 62 Loss: 0.18230322003364563 Acc: 0.9679\n",
            "Epoch: 63 Loss: 0.17757567763328552 Acc: 0.9679\n",
            "Epoch: 64 Loss: 0.17305877804756165 Acc: 0.9679\n",
            "Epoch: 65 Loss: 0.16873812675476074 Acc: 0.9679\n",
            "Epoch: 66 Loss: 0.16460074484348297 Acc: 0.9679\n",
            "Epoch: 67 Loss: 0.1606348603963852 Acc: 0.9679\n",
            "Epoch: 68 Loss: 0.15682977437973022 Acc: 0.9679\n",
            "Epoch: 69 Loss: 0.15317586064338684 Acc: 0.9744\n",
            "Epoch: 70 Loss: 0.14966431260108948 Acc: 0.9872\n",
            "Epoch: 71 Loss: 0.14628708362579346 Acc: 0.9872\n",
            "Epoch: 72 Loss: 0.14303676784038544 Acc: 0.9872\n",
            "Epoch: 73 Loss: 0.1399066150188446 Acc: 0.9872\n",
            "Epoch: 74 Loss: 0.13689038157463074 Acc: 0.9872\n",
            "Epoch: 75 Loss: 0.13398227095603943 Acc: 0.9872\n",
            "Epoch: 76 Loss: 0.1311769187450409 Acc: 0.9872\n",
            "Epoch: 77 Loss: 0.128469318151474 Acc: 0.9872\n",
            "Epoch: 78 Loss: 0.12585483491420746 Acc: 0.9872\n",
            "Epoch: 79 Loss: 0.12332916259765625 Acc: 0.9936\n",
            "Epoch: 80 Loss: 0.12088817358016968 Acc: 0.9936\n",
            "Epoch: 81 Loss: 0.11852804571390152 Acc: 1.0\n",
            "Epoch: 82 Loss: 0.11624521762132645 Acc: 1.0\n",
            "Epoch: 83 Loss: 0.11403627693653107 Acc: 1.0\n",
            "Epoch: 84 Loss: 0.11189805716276169 Acc: 1.0\n",
            "Epoch: 85 Loss: 0.10982753336429596 Acc: 1.0\n",
            "Epoch: 86 Loss: 0.10782185941934586 Acc: 1.0\n",
            "Epoch: 87 Loss: 0.10587833821773529 Acc: 1.0\n",
            "Epoch: 88 Loss: 0.1039944440126419 Acc: 1.0\n",
            "Epoch: 89 Loss: 0.10216771811246872 Acc: 1.0\n",
            "Epoch: 90 Loss: 0.10039588809013367 Acc: 1.0\n",
            "Epoch: 91 Loss: 0.09867675602436066 Acc: 1.0\n",
            "Epoch: 92 Loss: 0.09700827300548553 Acc: 1.0\n",
            "Epoch: 93 Loss: 0.09538846462965012 Acc: 1.0\n",
            "Epoch: 94 Loss: 0.09381543844938278 Acc: 1.0\n",
            "Epoch: 95 Loss: 0.09228740632534027 Acc: 1.0\n",
            "Epoch: 96 Loss: 0.09080266952514648 Acc: 1.0\n",
            "Epoch: 97 Loss: 0.08935960382223129 Acc: 1.0\n",
            "Epoch: 98 Loss: 0.08795665204524994 Acc: 1.0\n",
            "Epoch: 99 Loss: 0.08659233897924423 Acc: 1.0\n",
            "Epoch: 100 Loss: 0.08526523411273956 Acc: 1.0\n",
            "Epoch: 101 Loss: 0.0839739665389061 Acc: 1.0\n",
            "Epoch: 102 Loss: 0.08271729201078415 Acc: 1.0\n",
            "Epoch: 103 Loss: 0.08149392157793045 Acc: 1.0\n",
            "Epoch: 104 Loss: 0.08030268549919128 Acc: 1.0\n",
            "Epoch: 105 Loss: 0.07914245128631592 Acc: 1.0\n",
            "Epoch: 106 Loss: 0.07801210880279541 Acc: 1.0\n",
            "Epoch: 107 Loss: 0.07691062986850739 Acc: 1.0\n",
            "Epoch: 108 Loss: 0.07583700865507126 Acc: 1.0\n",
            "Epoch: 109 Loss: 0.07479029148817062 Acc: 1.0\n",
            "Epoch: 110 Loss: 0.07376954704523087 Acc: 1.0\n",
            "Epoch: 111 Loss: 0.07277389615774155 Acc: 1.0\n",
            "Epoch: 112 Loss: 0.07180246710777283 Acc: 1.0\n",
            "Epoch: 113 Loss: 0.07085450738668442 Acc: 1.0\n",
            "Epoch: 114 Loss: 0.06992916017770767 Acc: 1.0\n",
            "Epoch: 115 Loss: 0.06902571022510529 Acc: 1.0\n",
            "Epoch: 116 Loss: 0.06814344972372055 Acc: 1.0\n",
            "Epoch: 117 Loss: 0.06728167086839676 Acc: 1.0\n",
            "Epoch: 118 Loss: 0.06643971055746078 Acc: 1.0\n",
            "Epoch: 119 Loss: 0.0656169205904007 Acc: 1.0\n",
            "Epoch: 120 Loss: 0.06481270492076874 Acc: 1.0\n",
            "Epoch: 121 Loss: 0.06402644515037537 Acc: 1.0\n",
            "Epoch: 122 Loss: 0.0632576122879982 Acc: 1.0\n",
            "Epoch: 123 Loss: 0.06250564008951187 Acc: 1.0\n",
            "Epoch: 124 Loss: 0.0617699921131134 Acc: 1.0\n",
            "Epoch: 125 Loss: 0.061050184071063995 Acc: 1.0\n",
            "Epoch: 126 Loss: 0.06034572422504425 Acc: 1.0\n",
            "Epoch: 127 Loss: 0.059656135737895966 Acc: 1.0\n",
            "Epoch: 128 Loss: 0.05898099020123482 Acc: 1.0\n",
            "Epoch: 129 Loss: 0.05831984430551529 Acc: 1.0\n",
            "Epoch: 130 Loss: 0.057672273367643356 Acc: 1.0\n",
            "Epoch: 131 Loss: 0.057037897408008575 Acc: 1.0\n",
            "Epoch: 132 Loss: 0.05641632899641991 Acc: 1.0\n",
            "Epoch: 133 Loss: 0.05580716207623482 Acc: 1.0\n",
            "Epoch: 134 Loss: 0.05521008372306824 Acc: 1.0\n",
            "Epoch: 135 Loss: 0.05462472885847092 Acc: 1.0\n",
            "Epoch: 136 Loss: 0.054050762206315994 Acc: 1.0\n",
            "Epoch: 137 Loss: 0.0534878745675087 Acc: 1.0\n",
            "Epoch: 138 Loss: 0.05293576046824455 Acc: 1.0\n",
            "Epoch: 139 Loss: 0.05239409580826759 Acc: 1.0\n",
            "Epoch: 140 Loss: 0.051862623542547226 Acc: 1.0\n",
            "Epoch: 141 Loss: 0.05134105682373047 Acc: 1.0\n",
            "Epoch: 142 Loss: 0.05082913115620613 Acc: 1.0\n",
            "Epoch: 143 Loss: 0.050326570868492126 Acc: 1.0\n",
            "Epoch: 144 Loss: 0.049833156168460846 Acc: 1.0\n",
            "Epoch: 145 Loss: 0.0493486225605011 Acc: 1.0\n",
            "Epoch: 146 Loss: 0.048872750252485275 Acc: 1.0\n",
            "Epoch: 147 Loss: 0.04840531572699547 Acc: 1.0\n",
            "Epoch: 148 Loss: 0.04794609174132347 Acc: 1.0\n",
            "Epoch: 149 Loss: 0.047494884580373764 Acc: 1.0\n",
            "Epoch: 150 Loss: 0.047051478177309036 Acc: 1.0\n",
            "Epoch: 151 Loss: 0.046615686267614365 Acc: 1.0\n",
            "Epoch: 152 Loss: 0.04618730768561363 Acc: 1.0\n",
            "Epoch: 153 Loss: 0.04576617479324341 Acc: 1.0\n",
            "Epoch: 154 Loss: 0.04535209387540817 Acc: 1.0\n",
            "Epoch: 155 Loss: 0.04494490846991539 Acc: 1.0\n",
            "Epoch: 156 Loss: 0.044544436037540436 Acc: 1.0\n",
            "Epoch: 157 Loss: 0.04415053501725197 Acc: 1.0\n",
            "Epoch: 158 Loss: 0.04376303404569626 Acc: 1.0\n",
            "Epoch: 159 Loss: 0.043381787836551666 Acc: 1.0\n",
            "Epoch: 160 Loss: 0.04300665482878685 Acc: 1.0\n",
            "Epoch: 161 Loss: 0.042637478560209274 Acc: 1.0\n",
            "Epoch: 162 Loss: 0.042274124920368195 Acc: 1.0\n",
            "Epoch: 163 Loss: 0.04191647469997406 Acc: 1.0\n",
            "Epoch: 164 Loss: 0.04156439006328583 Acc: 1.0\n",
            "Epoch: 165 Loss: 0.04121774435043335 Acc: 1.0\n",
            "Epoch: 166 Loss: 0.04087641462683678 Acc: 1.0\n",
            "Epoch: 167 Loss: 0.04054027795791626 Acc: 1.0\n",
            "Epoch: 168 Loss: 0.04020923748612404 Acc: 1.0\n",
            "Epoch: 169 Loss: 0.03988316282629967 Acc: 1.0\n",
            "Epoch: 170 Loss: 0.03956194967031479 Acc: 1.0\n",
            "Epoch: 171 Loss: 0.039245493710041046 Acc: 1.0\n",
            "Epoch: 172 Loss: 0.03893370181322098 Acc: 1.0\n",
            "Epoch: 173 Loss: 0.038626473397016525 Acc: 1.0\n",
            "Epoch: 174 Loss: 0.038323692977428436 Acc: 1.0\n",
            "Epoch: 175 Loss: 0.03802528604865074 Acc: 1.0\n",
            "Epoch: 176 Loss: 0.03773115202784538 Acc: 1.0\n",
            "Epoch: 177 Loss: 0.037441205233335495 Acc: 1.0\n",
            "Epoch: 178 Loss: 0.037155359983444214 Acc: 1.0\n",
            "Epoch: 179 Loss: 0.036873530596494675 Acc: 1.0\n",
            "Epoch: 180 Loss: 0.03659563139081001 Acc: 1.0\n",
            "Epoch: 181 Loss: 0.03632159158587456 Acc: 1.0\n",
            "Epoch: 182 Loss: 0.03605133295059204 Acc: 1.0\n",
            "Epoch: 183 Loss: 0.0357847586274147 Acc: 1.0\n",
            "Epoch: 184 Loss: 0.03552182391285896 Acc: 1.0\n",
            "Epoch: 185 Loss: 0.03526245057582855 Acc: 1.0\n",
            "Epoch: 186 Loss: 0.035006556659936905 Acc: 1.0\n",
            "Epoch: 187 Loss: 0.03475409001111984 Acc: 1.0\n",
            "Epoch: 188 Loss: 0.0345049723982811 Acc: 1.0\n",
            "Epoch: 189 Loss: 0.034259140491485596 Acc: 1.0\n",
            "Epoch: 190 Loss: 0.034016530960798264 Acc: 1.0\n",
            "Epoch: 191 Loss: 0.03377709165215492 Acc: 1.0\n",
            "Epoch: 192 Loss: 0.0335407517850399 Acc: 1.0\n",
            "Epoch: 193 Loss: 0.033307451754808426 Acc: 1.0\n",
            "Epoch: 194 Loss: 0.03307715058326721 Acc: 1.0\n",
            "Epoch: 195 Loss: 0.03284977376461029 Acc: 1.0\n",
            "Epoch: 196 Loss: 0.03262527659535408 Acc: 1.0\n",
            "Epoch: 197 Loss: 0.032403614372015 Acc: 1.0\n",
            "Epoch: 198 Loss: 0.03218472748994827 Acc: 1.0\n",
            "Epoch: 199 Loss: 0.031968552619218826 Acc: 1.0\n",
            "Epoch: 200 Loss: 0.03175506368279457 Acc: 1.0\n",
            "Epoch: 201 Loss: 0.031544193625450134 Acc: 1.0\n",
            "Epoch: 202 Loss: 0.03133590891957283 Acc: 1.0\n",
            "Epoch: 203 Loss: 0.031130151823163033 Acc: 1.0\n",
            "Epoch: 204 Loss: 0.030926894396543503 Acc: 1.0\n",
            "Epoch: 205 Loss: 0.030726071447134018 Acc: 1.0\n",
            "Epoch: 206 Loss: 0.030527658760547638 Acc: 1.0\n",
            "Epoch: 207 Loss: 0.03033161163330078 Acc: 1.0\n",
            "Epoch: 208 Loss: 0.03013787604868412 Acc: 1.0\n",
            "Epoch: 209 Loss: 0.029946425929665565 Acc: 1.0\n",
            "Epoch: 210 Loss: 0.029757218435406685 Acc: 1.0\n",
            "Epoch: 211 Loss: 0.029570212587714195 Acc: 1.0\n",
            "Epoch: 212 Loss: 0.02938537485897541 Acc: 1.0\n",
            "Epoch: 213 Loss: 0.029202666133642197 Acc: 1.0\n",
            "Epoch: 214 Loss: 0.02902205102145672 Acc: 1.0\n",
            "Epoch: 215 Loss: 0.02884349785745144 Acc: 1.0\n",
            "Epoch: 216 Loss: 0.028666969388723373 Acc: 1.0\n",
            "Epoch: 217 Loss: 0.028492435812950134 Acc: 1.0\n",
            "Epoch: 218 Loss: 0.028319859877228737 Acc: 1.0\n",
            "Epoch: 219 Loss: 0.028149213641881943 Acc: 1.0\n",
            "Epoch: 220 Loss: 0.027980461716651917 Acc: 1.0\n",
            "Epoch: 221 Loss: 0.027813566848635674 Acc: 1.0\n",
            "Epoch: 222 Loss: 0.027648521587252617 Acc: 1.0\n",
            "Epoch: 223 Loss: 0.027485281229019165 Acc: 1.0\n",
            "Epoch: 224 Loss: 0.02732381783425808 Acc: 1.0\n",
            "Epoch: 225 Loss: 0.02716410532593727 Acc: 1.0\n",
            "Epoch: 226 Loss: 0.027006106451153755 Acc: 1.0\n",
            "Epoch: 227 Loss: 0.026849808171391487 Acc: 1.0\n",
            "Epoch: 228 Loss: 0.02669518068432808 Acc: 1.0\n",
            "Epoch: 229 Loss: 0.026542192324995995 Acc: 1.0\n",
            "Epoch: 230 Loss: 0.02639083005487919 Acc: 1.0\n",
            "Epoch: 231 Loss: 0.026241058483719826 Acc: 1.0\n",
            "Epoch: 232 Loss: 0.02609284780919552 Acc: 1.0\n",
            "Epoch: 233 Loss: 0.02594619244337082 Acc: 1.0\n",
            "Epoch: 234 Loss: 0.025801053270697594 Acc: 1.0\n",
            "Epoch: 235 Loss: 0.025657406076788902 Acc: 1.0\n",
            "Epoch: 236 Loss: 0.025515245273709297 Acc: 1.0\n",
            "Epoch: 237 Loss: 0.02537453919649124 Acc: 1.0\n",
            "Epoch: 238 Loss: 0.025235261768102646 Acc: 1.0\n",
            "Epoch: 239 Loss: 0.02509739063680172 Acc: 1.0\n",
            "Epoch: 240 Loss: 0.024960914626717567 Acc: 1.0\n",
            "Epoch: 241 Loss: 0.024825815111398697 Acc: 1.0\n",
            "Epoch: 242 Loss: 0.024692058563232422 Acc: 1.0\n",
            "Epoch: 243 Loss: 0.0245596282184124 Acc: 1.0\n",
            "Epoch: 244 Loss: 0.024428516626358032 Acc: 1.0\n",
            "Epoch: 245 Loss: 0.024298695847392082 Acc: 1.0\n",
            "Epoch: 246 Loss: 0.024170154705643654 Acc: 1.0\n",
            "Epoch: 247 Loss: 0.02404286153614521 Acc: 1.0\n",
            "Epoch: 248 Loss: 0.023916810750961304 Acc: 1.0\n",
            "Epoch: 249 Loss: 0.023791972547769547 Acc: 1.0\n",
            "Epoch: 250 Loss: 0.02366834692656994 Acc: 1.0\n",
            "Epoch: 251 Loss: 0.023545904085040092 Acc: 1.0\n",
            "Epoch: 252 Loss: 0.023424629122018814 Acc: 1.0\n",
            "Epoch: 253 Loss: 0.023304518312215805 Acc: 1.0\n",
            "Epoch: 254 Loss: 0.023185530677437782 Acc: 1.0\n",
            "Epoch: 255 Loss: 0.02306767925620079 Acc: 1.0\n",
            "Epoch: 256 Loss: 0.022950926795601845 Acc: 1.0\n",
            "Epoch: 257 Loss: 0.022835275158286095 Acc: 1.0\n",
            "Epoch: 258 Loss: 0.022720681503415108 Acc: 1.0\n",
            "Epoch: 259 Loss: 0.022607170045375824 Acc: 1.0\n",
            "Epoch: 260 Loss: 0.02249470166862011 Acc: 1.0\n",
            "Epoch: 261 Loss: 0.022383257746696472 Acc: 1.0\n",
            "Epoch: 262 Loss: 0.02227284014225006 Acc: 1.0\n",
            "Epoch: 263 Loss: 0.022163426503539085 Acc: 1.0\n",
            "Epoch: 264 Loss: 0.022055014967918396 Acc: 1.0\n",
            "Epoch: 265 Loss: 0.021947581321001053 Acc: 1.0\n",
            "Epoch: 266 Loss: 0.021841105073690414 Acc: 1.0\n",
            "Epoch: 267 Loss: 0.021735595539212227 Acc: 1.0\n",
            "Epoch: 268 Loss: 0.021631015464663506 Acc: 1.0\n",
            "Epoch: 269 Loss: 0.021527377888560295 Acc: 1.0\n",
            "Epoch: 270 Loss: 0.02142465114593506 Acc: 1.0\n",
            "Epoch: 271 Loss: 0.021322831511497498 Acc: 1.0\n",
            "Epoch: 272 Loss: 0.021221913397312164 Acc: 1.0\n",
            "Epoch: 273 Loss: 0.021121876314282417 Acc: 1.0\n",
            "Epoch: 274 Loss: 0.021022705361247063 Acc: 1.0\n",
            "Epoch: 275 Loss: 0.020924393087625504 Acc: 1.0\n",
            "Epoch: 276 Loss: 0.02082693763077259 Acc: 1.0\n",
            "Epoch: 277 Loss: 0.02073032036423683 Acc: 1.0\n",
            "Epoch: 278 Loss: 0.020634528249502182 Acc: 1.0\n",
            "Epoch: 279 Loss: 0.020539559423923492 Acc: 1.0\n",
            "Epoch: 280 Loss: 0.02044539526104927 Acc: 1.0\n",
            "Epoch: 281 Loss: 0.020352033898234367 Acc: 1.0\n",
            "Epoch: 282 Loss: 0.02025945670902729 Acc: 1.0\n",
            "Epoch: 283 Loss: 0.02016766183078289 Acc: 1.0\n",
            "Epoch: 284 Loss: 0.020076636224985123 Acc: 1.0\n",
            "Epoch: 285 Loss: 0.01998637057840824 Acc: 1.0\n",
            "Epoch: 286 Loss: 0.01989685371518135 Acc: 1.0\n",
            "Epoch: 287 Loss: 0.019808081910014153 Acc: 1.0\n",
            "Epoch: 288 Loss: 0.019720036536455154 Acc: 1.0\n",
            "Epoch: 289 Loss: 0.019632715731859207 Acc: 1.0\n",
            "Epoch: 290 Loss: 0.019546113908290863 Acc: 1.0\n",
            "Epoch: 291 Loss: 0.019460221752524376 Acc: 1.0\n",
            "Epoch: 292 Loss: 0.01937502808868885 Acc: 1.0\n",
            "Epoch: 293 Loss: 0.019290519878268242 Acc: 1.0\n",
            "Epoch: 294 Loss: 0.01920670084655285 Acc: 1.0\n",
            "Epoch: 295 Loss: 0.01912355050444603 Acc: 1.0\n",
            "Epoch: 296 Loss: 0.019041065126657486 Acc: 1.0\n",
            "Epoch: 297 Loss: 0.01895923912525177 Acc: 1.0\n",
            "Epoch: 298 Loss: 0.018878065049648285 Acc: 1.0\n",
            "Epoch: 299 Loss: 0.018797531723976135 Acc: 1.0\n",
            "Epoch: 300 Loss: 0.01871764101088047 Acc: 1.0\n",
            "Epoch: 301 Loss: 0.018638376146554947 Acc: 1.0\n",
            "Epoch: 302 Loss: 0.01855972781777382 Acc: 1.0\n",
            "Epoch: 303 Loss: 0.018481692299246788 Acc: 1.0\n",
            "Epoch: 304 Loss: 0.018404275178909302 Acc: 1.0\n",
            "Epoch: 305 Loss: 0.01832745037972927 Acc: 1.0\n",
            "Epoch: 306 Loss: 0.018251219764351845 Acc: 1.0\n",
            "Epoch: 307 Loss: 0.018175579607486725 Acc: 1.0\n",
            "Epoch: 308 Loss: 0.018100518733263016 Acc: 1.0\n",
            "Epoch: 309 Loss: 0.01802602969110012 Acc: 1.0\n",
            "Epoch: 310 Loss: 0.017952105030417442 Acc: 1.0\n",
            "Epoch: 311 Loss: 0.01787875033915043 Acc: 1.0\n",
            "Epoch: 312 Loss: 0.01780594512820244 Acc: 1.0\n",
            "Epoch: 313 Loss: 0.01773368939757347 Acc: 1.0\n",
            "Epoch: 314 Loss: 0.017661985009908676 Acc: 1.0\n",
            "Epoch: 315 Loss: 0.017590804025530815 Acc: 1.0\n",
            "Epoch: 316 Loss: 0.01752016320824623 Acc: 1.0\n",
            "Epoch: 317 Loss: 0.01745004579424858 Acc: 1.0\n",
            "Epoch: 318 Loss: 0.017380451783537865 Acc: 1.0\n",
            "Epoch: 319 Loss: 0.017311356961727142 Acc: 1.0\n",
            "Epoch: 320 Loss: 0.017242785543203354 Acc: 1.0\n",
            "Epoch: 321 Loss: 0.017174717038869858 Acc: 1.0\n",
            "Epoch: 322 Loss: 0.01710714027285576 Acc: 1.0\n",
            "Epoch: 323 Loss: 0.017040060833096504 Acc: 1.0\n",
            "Epoch: 324 Loss: 0.016973471269011497 Acc: 1.0\n",
            "Epoch: 325 Loss: 0.016907356679439545 Acc: 1.0\n",
            "Epoch: 326 Loss: 0.016841722652316093 Acc: 1.0\n",
            "Epoch: 327 Loss: 0.016776561737060547 Acc: 1.0\n",
            "Epoch: 328 Loss: 0.01671186089515686 Acc: 1.0\n",
            "Epoch: 329 Loss: 0.01664763130247593 Acc: 1.0\n",
            "Epoch: 330 Loss: 0.01658385433256626 Acc: 1.0\n",
            "Epoch: 331 Loss: 0.016520537436008453 Acc: 1.0\n",
            "Epoch: 332 Loss: 0.016457656398415565 Acc: 1.0\n",
            "Epoch: 333 Loss: 0.01639522984623909 Acc: 1.0\n",
            "Epoch: 334 Loss: 0.016333233565092087 Acc: 1.0\n",
            "Epoch: 335 Loss: 0.0162716805934906 Acc: 1.0\n",
            "Epoch: 336 Loss: 0.01621055230498314 Acc: 1.0\n",
            "Epoch: 337 Loss: 0.01614985056221485 Acc: 1.0\n",
            "Epoch: 338 Loss: 0.01608956605195999 Acc: 1.0\n",
            "Epoch: 339 Loss: 0.016029709950089455 Acc: 1.0\n",
            "Epoch: 340 Loss: 0.0159702580422163 Acc: 1.0\n",
            "Epoch: 341 Loss: 0.01591121405363083 Acc: 1.0\n",
            "Epoch: 342 Loss: 0.01585257798433304 Acc: 1.0\n",
            "Epoch: 343 Loss: 0.015794340521097183 Acc: 1.0\n",
            "Epoch: 344 Loss: 0.015736499801278114 Acc: 1.0\n",
            "Epoch: 345 Loss: 0.015679053962230682 Acc: 1.0\n",
            "Epoch: 346 Loss: 0.015621998347342014 Acc: 1.0\n",
            "Epoch: 347 Loss: 0.015565326437354088 Acc: 1.0\n",
            "Epoch: 348 Loss: 0.015509032644331455 Acc: 1.0\n",
            "Epoch: 349 Loss: 0.015453116968274117 Acc: 1.0\n",
            "Epoch: 350 Loss: 0.015397579409182072 Acc: 1.0\n",
            "Epoch: 351 Loss: 0.01534241158515215 Acc: 1.0\n",
            "Epoch: 352 Loss: 0.015287606045603752 Acc: 1.0\n",
            "Epoch: 353 Loss: 0.015233168378472328 Acc: 1.0\n",
            "Epoch: 354 Loss: 0.015179087407886982 Acc: 1.0\n",
            "Epoch: 355 Loss: 0.01512536033987999 Acc: 1.0\n",
            "Epoch: 356 Loss: 0.015071994625031948 Acc: 1.0\n",
            "Epoch: 357 Loss: 0.01501897070556879 Acc: 1.0\n",
            "Epoch: 358 Loss: 0.014966290444135666 Acc: 1.0\n",
            "Epoch: 359 Loss: 0.014913961291313171 Acc: 1.0\n",
            "Epoch: 360 Loss: 0.01486196555197239 Acc: 1.0\n",
            "Epoch: 361 Loss: 0.014810306951403618 Acc: 1.0\n",
            "Epoch: 362 Loss: 0.014758982695639133 Acc: 1.0\n",
            "Epoch: 363 Loss: 0.014707994647324085 Acc: 1.0\n",
            "Epoch: 364 Loss: 0.01465732604265213 Acc: 1.0\n",
            "Epoch: 365 Loss: 0.014606978744268417 Acc: 1.0\n",
            "Epoch: 366 Loss: 0.014556961134076118 Acc: 1.0\n",
            "Epoch: 367 Loss: 0.014507252722978592 Acc: 1.0\n",
            "Epoch: 368 Loss: 0.014457867480814457 Acc: 1.0\n",
            "Epoch: 369 Loss: 0.01440878864377737 Acc: 1.0\n",
            "Epoch: 370 Loss: 0.014360019937157631 Acc: 1.0\n",
            "Epoch: 371 Loss: 0.014311559498310089 Acc: 1.0\n",
            "Epoch: 372 Loss: 0.0142633942887187 Acc: 1.0\n",
            "Epoch: 373 Loss: 0.014215542934834957 Acc: 1.0\n",
            "Epoch: 374 Loss: 0.014167987741529942 Acc: 1.0\n",
            "Epoch: 375 Loss: 0.014120716601610184 Acc: 1.0\n",
            "Epoch: 376 Loss: 0.014073744416236877 Acc: 1.0\n",
            "Epoch: 377 Loss: 0.014027060940861702 Acc: 1.0\n",
            "Epoch: 378 Loss: 0.013980671763420105 Acc: 1.0\n",
            "Epoch: 379 Loss: 0.013934561982750893 Acc: 1.0\n",
            "Epoch: 380 Loss: 0.013888736255466938 Acc: 1.0\n",
            "Epoch: 381 Loss: 0.013843188062310219 Acc: 1.0\n",
            "Epoch: 382 Loss: 0.013797915540635586 Acc: 1.0\n",
            "Epoch: 383 Loss: 0.013752928003668785 Acc: 1.0\n",
            "Epoch: 384 Loss: 0.013708203099668026 Acc: 1.0\n",
            "Epoch: 385 Loss: 0.013663750141859055 Acc: 1.0\n",
            "Epoch: 386 Loss: 0.013619568198919296 Acc: 1.0\n",
            "Epoch: 387 Loss: 0.01357564888894558 Acc: 1.0\n",
            "Epoch: 388 Loss: 0.013531990349292755 Acc: 1.0\n",
            "Epoch: 389 Loss: 0.01348859816789627 Acc: 1.0\n",
            "Epoch: 390 Loss: 0.013445461168885231 Acc: 1.0\n",
            "Epoch: 391 Loss: 0.013402576558291912 Acc: 1.0\n",
            "Epoch: 392 Loss: 0.01335995178669691 Acc: 1.0\n",
            "Epoch: 393 Loss: 0.013317574746906757 Acc: 1.0\n",
            "Epoch: 394 Loss: 0.013275453820824623 Acc: 1.0\n",
            "Epoch: 395 Loss: 0.013233575969934464 Acc: 1.0\n",
            "Epoch: 396 Loss: 0.013191943056881428 Acc: 1.0\n",
            "Epoch: 397 Loss: 0.013150551356375217 Acc: 1.0\n",
            "Epoch: 398 Loss: 0.013109409250319004 Acc: 1.0\n",
            "Epoch: 399 Loss: 0.013068495318293571 Acc: 1.0\n",
            "Epoch: 400 Loss: 0.013027832843363285 Acc: 1.0\n",
            "Epoch: 401 Loss: 0.012987390160560608 Acc: 1.0\n",
            "Epoch: 402 Loss: 0.012947186827659607 Acc: 1.0\n",
            "Epoch: 403 Loss: 0.012907217256724834 Acc: 1.0\n",
            "Epoch: 404 Loss: 0.012867470271885395 Acc: 1.0\n",
            "Epoch: 405 Loss: 0.01282796636223793 Acc: 1.0\n",
            "Epoch: 406 Loss: 0.012788673862814903 Acc: 1.0\n",
            "Epoch: 407 Loss: 0.012749607674777508 Acc: 1.0\n",
            "Epoch: 408 Loss: 0.012710765935480595 Acc: 1.0\n",
            "Epoch: 409 Loss: 0.012672141194343567 Acc: 1.0\n",
            "Epoch: 410 Loss: 0.01263373252004385 Acc: 1.0\n",
            "Epoch: 411 Loss: 0.012595543637871742 Acc: 1.0\n",
            "Epoch: 412 Loss: 0.012557568028569221 Acc: 1.0\n",
            "Epoch: 413 Loss: 0.012519808486104012 Acc: 1.0\n",
            "Epoch: 414 Loss: 0.012482255697250366 Acc: 1.0\n",
            "Epoch: 415 Loss: 0.012444915249943733 Acc: 1.0\n",
            "Epoch: 416 Loss: 0.012407784350216389 Acc: 1.0\n",
            "Epoch: 417 Loss: 0.012370859272778034 Acc: 1.0\n",
            "Epoch: 418 Loss: 0.012334131635725498 Acc: 1.0\n",
            "Epoch: 419 Loss: 0.012297614477574825 Acc: 1.0\n",
            "Epoch: 420 Loss: 0.012261290103197098 Acc: 1.0\n",
            "Epoch: 421 Loss: 0.012225170619785786 Acc: 1.0\n",
            "Epoch: 422 Loss: 0.012189251370728016 Acc: 1.0\n",
            "Epoch: 423 Loss: 0.012153520248830318 Acc: 1.0\n",
            "Epoch: 424 Loss: 0.012117990292608738 Acc: 1.0\n",
            "Epoch: 425 Loss: 0.012082655914127827 Acc: 1.0\n",
            "Epoch: 426 Loss: 0.012047506868839264 Acc: 1.0\n",
            "Epoch: 427 Loss: 0.012012550607323647 Acc: 1.0\n",
            "Epoch: 428 Loss: 0.01197778433561325 Acc: 1.0\n",
            "Epoch: 429 Loss: 0.011943201534450054 Acc: 1.0\n",
            "Epoch: 430 Loss: 0.011908805929124355 Acc: 1.0\n",
            "Epoch: 431 Loss: 0.01187459472566843 Acc: 1.0\n",
            "Epoch: 432 Loss: 0.01184056419879198 Acc: 1.0\n",
            "Epoch: 433 Loss: 0.011806723661720753 Acc: 1.0\n",
            "Epoch: 434 Loss: 0.011773055419325829 Acc: 1.0\n",
            "Epoch: 435 Loss: 0.01173956599086523 Acc: 1.0\n",
            "Epoch: 436 Loss: 0.01170625165104866 Acc: 1.0\n",
            "Epoch: 437 Loss: 0.011673121713101864 Acc: 1.0\n",
            "Epoch: 438 Loss: 0.011640154756605625 Acc: 1.0\n",
            "Epoch: 439 Loss: 0.011607374995946884 Acc: 1.0\n",
            "Epoch: 440 Loss: 0.011574755422770977 Acc: 1.0\n",
            "Epoch: 441 Loss: 0.011542311869561672 Acc: 1.0\n",
            "Epoch: 442 Loss: 0.011510034091770649 Acc: 1.0\n",
            "Epoch: 443 Loss: 0.011477921158075333 Acc: 1.0\n",
            "Epoch: 444 Loss: 0.011445984244346619 Acc: 1.0\n",
            "Epoch: 445 Loss: 0.011414210312068462 Acc: 1.0\n",
            "Epoch: 446 Loss: 0.011382597498595715 Acc: 1.0\n",
            "Epoch: 447 Loss: 0.011351149529218674 Acc: 1.0\n",
            "Epoch: 448 Loss: 0.011319863609969616 Acc: 1.0\n",
            "Epoch: 449 Loss: 0.011288736015558243 Acc: 1.0\n",
            "Epoch: 450 Loss: 0.01125776395201683 Acc: 1.0\n",
            "Epoch: 451 Loss: 0.011226956732571125 Acc: 1.0\n",
            "Epoch: 452 Loss: 0.011196298524737358 Acc: 1.0\n",
            "Epoch: 453 Loss: 0.011165806092321873 Acc: 1.0\n",
            "Epoch: 454 Loss: 0.01113546546548605 Acc: 1.0\n",
            "Epoch: 455 Loss: 0.011105276644229889 Acc: 1.0\n",
            "Epoch: 456 Loss: 0.011075246147811413 Acc: 1.0\n",
            "Epoch: 457 Loss: 0.011045356281101704 Acc: 1.0\n",
            "Epoch: 458 Loss: 0.011015619151294231 Acc: 1.0\n",
            "Epoch: 459 Loss: 0.010986040346324444 Acc: 1.0\n",
            "Epoch: 460 Loss: 0.01095659751445055 Acc: 1.0\n",
            "Epoch: 461 Loss: 0.010927308350801468 Acc: 1.0\n",
            "Epoch: 462 Loss: 0.010898158885538578 Acc: 1.0\n",
            "Epoch: 463 Loss: 0.0108691630885005 Acc: 1.0\n",
            "Epoch: 464 Loss: 0.010840306058526039 Acc: 1.0\n",
            "Epoch: 465 Loss: 0.010811587795615196 Acc: 1.0\n",
            "Epoch: 466 Loss: 0.010783018544316292 Acc: 1.0\n",
            "Epoch: 467 Loss: 0.01075458899140358 Acc: 1.0\n",
            "Epoch: 468 Loss: 0.01072629913687706 Acc: 1.0\n",
            "Epoch: 469 Loss: 0.010698139667510986 Acc: 1.0\n",
            "Epoch: 470 Loss: 0.010670123621821404 Acc: 1.0\n",
            "Epoch: 471 Loss: 0.010642238892614841 Acc: 1.0\n",
            "Epoch: 472 Loss: 0.010614501312375069 Acc: 1.0\n",
            "Epoch: 473 Loss: 0.010586889460682869 Acc: 1.0\n",
            "Epoch: 474 Loss: 0.010559415444731712 Acc: 1.0\n",
            "Epoch: 475 Loss: 0.010532066226005554 Acc: 1.0\n",
            "Epoch: 476 Loss: 0.010504860430955887 Acc: 1.0\n",
            "Epoch: 477 Loss: 0.010477781295776367 Acc: 1.0\n",
            "Epoch: 478 Loss: 0.010450830683112144 Acc: 1.0\n",
            "Epoch: 479 Loss: 0.010424003936350346 Acc: 1.0\n",
            "Epoch: 480 Loss: 0.01039731316268444 Acc: 1.0\n",
            "Epoch: 481 Loss: 0.010370748117566109 Acc: 1.0\n",
            "Epoch: 482 Loss: 0.010344311594963074 Acc: 1.0\n",
            "Epoch: 483 Loss: 0.010317991487681866 Acc: 1.0\n",
            "Epoch: 484 Loss: 0.01029181107878685 Acc: 1.0\n",
            "Epoch: 485 Loss: 0.010265741497278214 Acc: 1.0\n",
            "Epoch: 486 Loss: 0.010239796712994576 Acc: 1.0\n",
            "Epoch: 487 Loss: 0.01021397951990366 Acc: 1.0\n",
            "Epoch: 488 Loss: 0.010188281536102295 Acc: 1.0\n",
            "Epoch: 489 Loss: 0.010162701830267906 Acc: 1.0\n",
            "Epoch: 490 Loss: 0.010137243196368217 Acc: 1.0\n",
            "Epoch: 491 Loss: 0.010111905634403229 Acc: 1.0\n",
            "Epoch: 492 Loss: 0.010086683556437492 Acc: 1.0\n",
            "Epoch: 493 Loss: 0.01006158348172903 Acc: 1.0\n",
            "Epoch: 494 Loss: 0.010036585852503777 Acc: 1.0\n",
            "Epoch: 495 Loss: 0.010011717677116394 Acc: 1.0\n",
            "Epoch: 496 Loss: 0.00998696032911539 Acc: 1.0\n",
            "Epoch: 497 Loss: 0.009962317533791065 Acc: 1.0\n",
            "Epoch: 498 Loss: 0.009937791153788567 Acc: 1.0\n",
            "Epoch: 499 Loss: 0.009913370013237 Acc: 1.0\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import SGD\n",
        "\n",
        "def accuracy(pred, label):\n",
        "  # TODO: Implement the accuracy function. This function takes as input a \n",
        "  # pred tensor (the resulting tensor after sigmoid) and a label \n",
        "  # tensor (torch.LongTensor). Predicted values greater than 0.5 are \n",
        "  # classified as label 1, else they are classified as label 0.\n",
        "  # The returned accuracy should be rounded to 4 decimal places. \n",
        "  # For example, accuracy 0.82956 will be rounded to 0.8296.\n",
        "\n",
        "  accu = 0.0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  accu = (torch.round(pred) == label).sum() / label.size(0)\n",
        "  accu = round(accu.item(), 4)\n",
        "  #########################################\n",
        "\n",
        "  return accu\n",
        "\n",
        "def train(model, loss_fn, sigmoid, train_label, train_edge):\n",
        "  # TODO: Train the embedding layer here. You need to implement: \n",
        "  # (1) Run the model with the proper input\n",
        "  # (2) Feed the model's output into the loss_fn\n",
        "  # (3) Print both loss and accuracy of each epoch \n",
        "  # (as a sanity check, the loss should decrease during training)\n",
        "  # \n",
        "  # During testing feel free to change the number of epochs and learning rate.\n",
        "  \n",
        "  epochs = 500\n",
        "  learning_rate = 0.1\n",
        "\n",
        "  optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "  for i in range(epochs):\n",
        "\n",
        "    ############# Your code here ############\n",
        "    ## Note: See the training steps above!\n",
        "    result = model(train_edge)\n",
        "    optimizer.zero_grad()  # Clear gradients.\n",
        "    \n",
        "    \n",
        "\n",
        "    loss = loss_fn(result, train_label)\n",
        "    # print(\"Epoch:\", i, \"Loss:\", loss.item())\n",
        "    print(\"Epoch:\", i, \"Loss:\", loss.item(), \n",
        "          \"Acc:\", accuracy(result, train_label))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    #########################################\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  loss_fn = nn.BCELoss()\n",
        "  sigmoid = nn.Sigmoid()\n",
        "\n",
        "  # Generate the positive and negative labels\n",
        "  pos_label = torch.ones(pos_edge_index.shape[1], )\n",
        "  neg_label = torch.zeros(neg_edge_index.shape[1], )\n",
        "\n",
        "  # Concat positive and negative labels into one tensor\n",
        "  train_label = torch.cat([pos_label, neg_label], dim=0)\n",
        "\n",
        "  # Concat positive and negative edges into one tensor\n",
        "  # Since the network is very small, we do not split the edges into val/test sets\n",
        "  train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
        "\n",
        "  model = EmbModel(emb)\n",
        "\n",
        "  train(model, loss_fn, sigmoid, train_label, train_edge)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_emb = emb(train_edge)\n",
        "dot_product = torch.sum(node_emb[0] * node_emb[1], -1)\n",
        "sig = nn.Sigmoid()\n",
        "out = sig(dot_product)\n",
        "out"
      ],
      "metadata": {
        "id": "IfFuqSYleVrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa16f93-f591-4f67-e9a5-613e2e0f898d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9.9901e-01, 9.9686e-01, 9.9728e-01, 9.9843e-01, 9.9026e-01, 9.9461e-01,\n",
              "        9.8965e-01, 9.7853e-01, 9.8288e-01, 9.8589e-01, 9.7960e-01, 9.8338e-01,\n",
              "        9.9242e-01, 9.7906e-01, 9.9627e-01, 9.9132e-01, 9.9133e-01, 9.9501e-01,\n",
              "        9.9699e-01, 9.8819e-01, 9.9492e-01, 9.9910e-01, 9.8859e-01, 9.9184e-01,\n",
              "        9.9122e-01, 9.9982e-01, 9.8915e-01, 9.8327e-01, 9.9865e-01, 9.8409e-01,\n",
              "        9.8379e-01, 9.7486e-01, 9.9615e-01, 9.8393e-01, 9.8781e-01, 9.9124e-01,\n",
              "        9.9380e-01, 9.8616e-01, 9.9426e-01, 9.9178e-01, 9.8806e-01, 9.9936e-01,\n",
              "        9.9296e-01, 9.8113e-01, 9.8971e-01, 9.7786e-01, 9.9107e-01, 9.9089e-01,\n",
              "        9.8703e-01, 9.9481e-01, 9.7810e-01, 9.8918e-01, 9.8703e-01, 9.8936e-01,\n",
              "        9.8636e-01, 9.9159e-01, 9.9278e-01, 9.7751e-01, 9.9844e-01, 9.9353e-01,\n",
              "        9.9091e-01, 9.8826e-01, 9.7827e-01, 9.9023e-01, 9.9379e-01, 9.9307e-01,\n",
              "        9.9840e-01, 9.8800e-01, 9.8441e-01, 9.9718e-01, 9.8953e-01, 9.9093e-01,\n",
              "        9.9624e-01, 9.9193e-01, 9.8751e-01, 9.7115e-01, 9.8773e-01, 9.9999e-01,\n",
              "        1.4051e-02, 1.4314e-02, 3.0906e-03, 2.8382e-03, 1.7008e-02, 1.3809e-02,\n",
              "        1.5084e-02, 9.4111e-03, 2.0099e-02, 7.3748e-05, 1.7611e-02, 6.8963e-03,\n",
              "        2.2675e-02, 1.6257e-03, 1.8900e-02, 9.5653e-03, 1.5917e-02, 1.5501e-02,\n",
              "        5.4410e-03, 5.8445e-03, 2.6920e-02, 5.0012e-04, 1.1855e-02, 2.0151e-02,\n",
              "        5.6208e-04, 1.9704e-02, 4.4206e-03, 1.5074e-02, 2.7867e-03, 2.1251e-03,\n",
              "        1.0616e-02, 3.9804e-03, 1.0195e-05, 1.7601e-02, 1.3610e-02, 4.6728e-04,\n",
              "        6.6378e-03, 2.6079e-03, 3.8585e-04, 4.0238e-03, 1.1995e-02, 1.3026e-03,\n",
              "        1.5559e-02, 1.5037e-02, 1.6438e-02, 7.0338e-03, 1.1067e-02, 1.5503e-02,\n",
              "        9.2720e-03, 5.3573e-03, 2.3538e-03, 6.1357e-03, 1.2451e-02, 9.5168e-04,\n",
              "        6.3011e-04, 1.2644e-02, 1.2905e-02, 1.6675e-02, 1.3607e-02, 2.0212e-02,\n",
              "        2.3571e-03, 9.7780e-03, 1.9322e-03, 1.1187e-02, 1.3836e-03, 1.1864e-02,\n",
              "        3.2843e-03, 1.1680e-02, 5.7862e-03, 1.6153e-03, 8.8387e-03, 1.1834e-02,\n",
              "        2.8520e-04, 1.3438e-02, 9.4850e-03, 6.6784e-03, 1.2465e-02, 1.2654e-02],\n",
              "       grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62LuURV24Jjk"
      },
      "source": [
        "## **Saving Your Model Predictions**!\n",
        "After you have successfully trained your embedding model, run the cell below to save your model's predictions on the training data. The function below will generate and save a csv file called *model_predictions.csv* to the local Colab files folder. This folder can be accessed by clicking the *Folder* icon on the left panel underneath the *Table of contents*, *Find and replace*, and *Code snippets* icons. \n",
        "\n",
        "When submitting this Colab you will have to download your model's predictions and submit them along with your Colab ipython notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7Jjz5J1W4GLj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def save_model_results(emb_model, train_label, train_edge):\n",
        "  \"\"\"\n",
        "    Helper function to save the model predictions and data\n",
        "    labels to a csv file for submission.\n",
        "  \"\"\"\n",
        "\n",
        "  # Generate model predictions\n",
        "  pred = emb_model(train_edge).detach()\n",
        "\n",
        "  # Create a pandas datafram with columns\n",
        "  # model_pred | binary_pred | label\n",
        "  data = {}\n",
        "  data['model_pred'] = pred\n",
        "  data['binary_pred'] = np.where(pred > 0.5, 1.0, 0.0)\n",
        "  data['label'] = train_label.detach()\n",
        "\n",
        "  df = pd.DataFrame(data=data)\n",
        "  # Save to csv\n",
        "  df.to_csv('model_predictions.csv', sep=',', index=False)\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  save_model_results(model, train_label, train_edge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX2PSXnTDiNi"
      },
      "source": [
        "## Visualize the final node embeddings\n",
        "Now you can visually compare our embeddings with the embeddings before training. After training, you should oberserve that the two classes are more evidently separated. Note that since we are reducing the dimensionality of our embeddings from **16 --> 2** you may not see perfect linear sepeartion.\n",
        "\n",
        "\n",
        "Overall, visualizing model / node embeddings is a great sanity check for your implementation, in addition to tracking the model's accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "MtNgl4VhYKow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "82eeeac5-2db6-4a32-a943-4684a38bbcdd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Visualize the final learned embedding\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  visualize_emb(emb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTNyrAoSVeq9"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_E7J_GkVhY_"
      },
      "source": [
        "You will need to submit two files on Gradescope to complete this notebook. \n",
        "\n",
        "1.   Your completed *XCS224W_Colab1.ipynb*. From the \"File\" menu select \"Download .ipynb\" to save a local copy of your completed Colab. \n",
        "2.   Your model predictions. Open up the local Colab file folder (by selecting the Folder icon on the left panel) and download *model_predictions.csv* \n",
        "\n",
        "For submitting your work, zip the files downloaded in steps 1 and 2 above and submit to gradescope. **NOTE:** DO NOT rename any of the downloaded files. The file names should be *XCS224W_Colab1.ipynb* and *model_predictions.csv*.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Copie de XCS224W_Colab1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}